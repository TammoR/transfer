#    -*- mode: org -*-


Archived entries from file /media/tammo/data/ohba_symbolic/presentation/index.org


* Concatenated across all sessions and subject
:PROPERTIES:
:ARCHIVE_TIME: 2015-08-04 Tue 15:35
:ARCHIVE_FILE: /media/tammo/data/ohba_symbolic/presentation/index.org
:ARCHIVE_OLPATH: HMM on sensor space MEG
:ARCHIVE_CATEGORY: index
:END:


- HMM on EEG data in source space failed.

# * Apache Spark
#   :PROPERTIES:
#   :reveal_background: figures/spark-logo5.png
#   :reveal_background_size: 600px
#   :reveal_background_trans: fading
#   :END:

#   - Originated 2009 at UC Berkeley
#   - Most active Apache project and most active open source big data project (by the number of contributors)
#   - Allows repeated queries to data in cluster memory
#     - For *iterative* algorithms.
#     - For *interactive* queries.
#     - Hadoop: .map() -> .reduce() -> write to disk
#   - Works on top of various cluster managers and data storage systems
#   - Written in Scala, but APIs availabe in Python, Java, R. 

# #+BEGIN_NOTES
#   - Still developed in very 'academic spirit'.
#   - Cluster manager: Standalone, Hadoop YARN, Apache Mesos
#   - Storage systems: HDFS, Amazon S3...
# #+END_NOTES
		  
# ** Resilient Distributed Dataset (RDD) - Sparks main abstraction
#   :PROPERTIES:
#   :reveal_background: figures/spark-logo5.png
#   :reveal_background_size: 700px
#   :reveal_background_trans: fading
#   :END:

# #+ATTR_REVEAL: :frag (highlight-blue highlight-blue highlight-blue highlight-blue highlight-blue highlight-blue) :frag_idx (1 2 3 4 5 6)
# - A read only collection of Objects (e.g. lists, arrays, strings, variables, ...)
# - Partitioned across machines
# - Undergoing parallel operations
# - Resides in Memory
# - Evaluation is *lazy*
# - RDDs are ephemeral, but their lineage is tracked.
# # - Computation happens were the data i

# ** Processing a text file with the Spark Python API
#   :PROPERTIES:
#   :reveal_background: figures/spark-logo5.png
#   :reveal_background_size: 800px
#   :reveal_background_trans: fading
#   :END:

# #+BEGIN_SRC 
# ##fileformat=VCFv4.1
# ##dummy example of a genotype file 				
# #CHROM	POS     ID     REF	ALT	QUAL	HG1	HG2	HG3	HG4   ...	
# 22	160575	rs58769  A	G	PASS	1|0	0|0     0|0	0|0   ...
# 22	160576	rs58762	 G	A,C	PASS	0|0	2|2	0|0	0|0   ...
# 22	160577	rs58763	 C	TATA	PASS	1|1	0|0	0|0	0|1   ...
# 22	160578	rs58764	 C	T       PASS	0|0	0|0	0|0	0|0   ...
# 22	160579	rs58767	 C	A	PASS	0|0	0|0	0|0	0|0   ...
# .       .       .        .      .       .       .       .       .       .     ...
# .       .       .        .      .       .       .       .       .       .     ...
# #+END_SRC 

# #+ATTR_REVEAL: :frag t 
# Clean up comments and columns 
# #+ATTR_REVEAL: :frag t 
#    #+BEGIN_SRC python
#    genotype = spark.textFile('input.txt')
#    genotype = genotype.filter(lambda row: row[0] != '#').map(lambda row: row.split('\t'))
#    #+END_SRC

# #+ATTR_REVEAL: :frag t 
# If we force computation, the output reads:

# #+ATTR_REVEAL: :frag t 
# #+BEGIN_SRC python
# [[22, 160575, 'rs58769', 'A', 'G',    'PASS', '1|0', '0|0','0|0','0|0']
#  [22, 160576, 'rs58762', 'G', 'A,C',  'PASS', '0|0', '2|2','0|0','0|0']
#  [22, 160577, 'rs58763', 'C', 'TATA', 'PASS', '1|1', '0|0','0|0','0|1']
#  [22, 160578, 'rs58764', 'C', 'T',    'PASS', '0|0', '0|0','0|0','0|0']
#  [22, 160579, 'rs58767', 'C', 'A',    'PASS', '0|0', '0|0','0|0','0|0']]
# #+END_SRC


# #+REVEAL: split

# #+REVEAL_HTML: <font color="red"><div align="left">Genotype data (size: 1e3 x 4e7)</div></font>
# #+BEGIN_SRC python
# POS   ID       REFtoALT HG1     HG2     HG3     HG4     HG5     HG6  ... 
# 16077 rs587624 CtoTATA  2       0       0       1       0       1    ...    
# 16081 rs587628 GtoACG   1       0       1       0       1       0    ... 
# 16081 rs587628 GtoT     0       0       0       0       0       0    ...    
# 16085 rs587832 AtoG     0       0       0       0       0       1    ... 
# 16078 rs587625 CtoT     0       0       0       0       0       0    ...    
# 16082 rs587629 GtoT     0       0       0       0       0       0    ...    
# 16075 rs587622 AtoG     1       0       0       0       0       0    ...    
# 16079 rs587626 CtoA     0       0       0       0       0       0    ...    
# 16083 rs587630 GtoT     0       0       0       0       0       0    ...    
# #+END_SRC


# #+REVEAL_HTML: <font color="blue"><div align="left">Expression data (size: 1e3 x 2e4)</div></font>
# #+BEGIN_SRC python
# CHROM START    END      ENTREZ_ID DESCRIPTION  HG1        HG2      HG3      HG4   ...
# chr15 25302005 25302102 133415    SNORD116_3   -1.5092   -1.4306  0.5507   1.3763 ...
# chr15 25319259 25319363 133422    SNORD116_7   0.4219    0.80277  -0.6127  -0.905 ...
# chr15 25307478 25307575 123417    SNORD116_4   -0.0378   -0.28113 -1.0425  -1.020 ...
# chr15 25321074 25321168 103423    SNORD116_8   0.7146    1.0656   0.7997   -1.114 ... 
# chr15 25296622 25296719 103413    SNORD116_1   -1.374    1.0361   0.8036   1.2499 ...
# chr15 25315577 25315674 103420    SNORD116_5   -0.0264   0.288    0.0005   1.3715 ...
# chr15 25322196 25322290 103424    SNORD116_9   -1.702    -0.7864  1.0003   -0.489 ...
# chr15 25299355 25299452 103414    SNORD116_2   0.143     -1.2503  1.8367   -0.772 ...

# #+END_SRC

# ** Spark data frames
#   :PROPERTIES:
#   :reveal_background: figures/spark-logo5.png
#   :reveal_background_size: 900px 
#   :reveal_background_trans: fading
#   :END:

#    - Like data frames in R or python pandas library
#    - Allow all common relational operations (select, filter, join, ...)
#    - Supports SQL queries.

# #+ATTR_REVEAL: :frag t 
# Find a particular SNP

# #+ATTR_REVEAL: :frag t 
# #+BEGIN_SRC python
# SNP_df.filter(SNP_df.POS == 160576).show()
# #+END_SRC

# #+ATTR_REVEAL: :frag t
# #+BEGIN_SRC python
# POS    ID      REFtoALT HG1 HG2 HG3 HG4 HG5 HG6 HG7 HG8 ...
# 160576 rs58769 GtoA     0   0   0   0   0   0   0   0   ...
# 160576 rs58769 GtoC     0   0   0   0   0   0   0   0   ...
# #+END_SRC


# #+ATTR_REVEAL: :frag t 
# Find polymorphisms for a particular sample
# #+ATTR_REVEAL: :frag t 
# #+BEGIN_SRC python
# SNP_df.where(SNP_df[HG7] >= 1).show()
# #+END_SRC

# #+ATTR_REVEAL: :frag t 
# #+BEGIN_SRC python
# POS    ID      REFtoALT HG1 HG2 HG3 HG4 HG5 HG6 HG7 HG8 ...
# 160577 rs58764 CtoTATA  2   0   0   1   0   1   1   0   ...     
# 160581 rs58768 GtoACG   1   0   1   0   1   0   2   0   ...      
# #+END_SRC


# # show output and example queries

# * eQTL Analysis in Spark
# ** Example Query
# Genotype and expression data have been loaded into data frames.
# #+BEGIN_SRC python
# SNP_df = load_genotype_data('genotype.vcf')
# epx_df = load_expression_data('expression.gct')
# gene_ids = 'all'
# eQTLs = cartesian_product_method(SNP_df, exp_df,\
#                                          gene_ids,\
#                                          max_distance=1e6,\
#                                          sign_level = .6,\
#                                          outname = 'my_eQTL_analysis.out')

# eQTLs.show()
# #+END_SRC

# #+ATTR_REVEAL: :frag t
# ... wait a minute ...

# #+ATTR_REVEAL: :frag t
# #+BEGIN_SRC python
# CHROM ENTREZ_ID SNP_POSITION REFtoALT CORR  
# chr15 1033415   16051        GtoACG   0.7368807  
# chr15 1033415   16055        AtoG     0.6830418  
# chr15 1033422   16055        AtoG     0.6285847  
# chr15 1033422   16059        CtoA     0.6669201  
# chr15 1033415   16075        AtoG     0.7927461  
# chr15 1033415   16059        CtoA     0.6015037  
# chr15 1033422   16050        CtoA     0.6285847  
# chr15 1033415   16050        CtoA     0.8927461  
# chr15 1033423   16055        AtoG     0.6175155  
# chr15 1033423   16059        CtoA     0.7690654  
# chr15 1033423   16050        CtoA     0.6175155  
# #+END_SRC

# ** Data Layout
# #+REVEAL_HTML: <img data-src="/home/tammo/Dropbox/eQTLs/git_reveal/figures/tikz_test-crop-1.png" alt="Mountain View" style="width:700px;height:500px;">

# - Expression: vertical factor 20
# - Genotype: vertical factor 10,000

   
# ** Cis Analysis with Cartesian Product Method
# 1. _Load and cache_ the data into *distributed* RDDs
# 2. Filter genotype and expression data, to contain identical samples in identical order.
# 3. Filter for genes or SNPs that are not expressed in at least 5 (or 5%) of the samples.
# 4. Translate genotype codes to integer numbers (e.g. 0|1 → 1 or 1|1 → 2).
# 5. Materialize gene expression data and broadcast a copy to every worker node.

# _Iterate_ for every desired gene:

# 1. _Filter_ SNPs to be close enough (cis) to the current gene.
# 2. Map the correlation function onto the RDD of remaining SNPs.
#    - Calculate Spearman correlation and (if applicable) p-value.
#    - Return a tuple: (p-value, SNP-index, gene-index)

# ** Cis Analysis: Benchmark
#      [[./figures/benchmark_cpm_1_1.png]]

# ** Sparse Vector Method
# Just like before, but the SNP representation exploits the sparsity.

# Prior representation:
# #+BEGIN_SRC python
# POS    ID      REFtoALT HG1 HG2 HG3 HG4 HG5 HG6 HG7 HG8 ...
# 160577 rs58764 CtoTATA  0   0   0   1   0   0   0   0   ...     
# 160581 rs58768 GtoACG   0   0   2   0   1   0   0   0   ...      
# #+END_SRC

# #+ATTR_REVEAL: :frag t 
# Sparse representation of the same data:
# #+ATTR_REVEAL: :frag t 
# #+BEGIN_SRC python
# ID       HG1 HG2 HG3 HG4 HG5 HG6 HG7 HG8 ...
# rs58764  SparseVector(1, {3:1})            
# rs58768  SparseVector(2, {2:2, 4:1})     
# #+END_SRC

# ** Sparse cis Analysis: Benchmark
# #+REVEAL_HTML: <img data-src="/home/tammo/Dropbox/eQTLs/report/figures/cis_benchmark-crop-1.png" alt="Mountain View" style="width:800px;height:600px;">

# ** Trans Analysis
# - Roughly the same first steps as the cis algorithm.
# - Not necessary to iterate over every gene and pick out the relevant SNPs every time.
# - Instead of an array of desired genes, the SNP RDD becomes the pivotal object of computation.
# - This greatly improves the effective degree of parallelism.

# ** Trans Analysis: Benchmarks 1
# #+REVEAL_HTML: <img data-src="/home/tammo/Dropbox/eQTLs/report/figures/full_analysis_SNPtimings-crop-1.png" alt="Mountain View" style="width:900px;height:600px;">
# - 3-4 orders of magnitude faster than the trans analysis.

# ** Trans Analysis: Benchmarks 2
# #+REVEAL_HTML: <img data-src="/home/tammo/Dropbox/eQTLs/report/figures/full_analysis_core_timings-crop-1.png" alt="Mountain View" style="width:800px;height:600px;">

# ** Trans Analysis: Benchmarks 3
# - A full trans analysis of the 1000 Genomes data on 786 worker nodes, each with 16 GB memory, calculating more than 3 × 10¹¹ correlations, takes approximately 90 minutes.
# * Results
# #+REVEAL_HTML: <img data-src="/home/tammo/Dropbox/eQTLs/report/figures/circos2.png" alt="Mountain View" style="width:600px;height:600px;">

# * Conclusion & Discussion
# - We developed a scalable algorithm for trans eQTL analysis
# - Spark is very well suited to emberassingly parallel problems, and potentially also for more complex problems.
# - Spark is under vivid development. Libraries for machine learning and stream processing are becoming mature.
# - Spark is easy to work with (compared to other parallel platforms) and offers APIs in scala (native), python, java, and R.
# - For this type of analysis GPUs could be a viable alternative

# ** Acknowledgments
# Thanks to
# - Industrial supervisors: *Satu Nahkuri* and *Barbara Endler-Jobst* at Roche
# - Supervisors in Oxford: *Chris Yau* and *Peter Humburg*
# - The whole Roche pREDi Data Science team
# - Our funding: EPSRC

# # * Future Work
# # #+ATTR_REVEAL: :frag (highlight-green highlight-red highlight-red highlight-blue highlight-blue highlight-blue)
# #   - Implement Matrix method to avoid iterations.
# #   - Improve the algorithm, especially the search of cis SNPs.
# #   - Perform larger analyses (e.g. across chromosomes).
# #   - Statistical tests
# #     + Simple significance test with multiple comparsion correction.
# #     + Resampling tests, Bootstrap.
# #   - Account for covarites (e.g. by principal componente analysis)
# #   - Stratified analysis for gender, ethnicity, ...

